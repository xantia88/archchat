Для расположения АС уровня критичности Mission Critical и Business Critical, уровень надежности ЦОД должен быть сертифицирован/соответствовать классу надежности не ниже Tier III,по классификации Uptime Institute Tier Standard.
ЦОД должен размещаться на территории Российской Федерации или на территории регистрации компании.
Несущая способность конструкций в машинных залах ЦОД должна быть достаточной для того, чтобы выдерживать как распределённую, так и сосредоточенную нагрузку от установленного оборудования.
Ограждающие строительные конструкции (стены, перекрытия) машинного зала или специализированного помещения должны быть устойчивы к взлому не ниже 1-го класса по ВС1992 (приложение 2).
Отделка потолков, стен и полов машинных залов должна способствовать минимизации процесса пылеобразования в помещении и обеспечивать требования по эксплуатации ИТ-оборудования. Минимум: • Окрашенные не пылеобразующими составами внутренние поверхности залов  • Отсутствие поверхностей с открытым бетоном.
Стойки с ИТ-оборудованием должны быть сгруппированы и размещены в выделенных машинных залах по принципу организации «горячих» и «холодных» коридоров. Неиспользуемые промежутки в ИТ-стойках заполняются заглушками для предотвращения перетекания горячего воздуха в «холодный коридор».
При размещении стойки следует учитывать наличие сервисного пространства для установки и обслуживания ИТ-оборудования. • Беспрепятственное открытие дверей стоек. • Наличие необходимого пространства для монтажа  и обслуживания устанавливаемого оборудования (определяется по спецификации/документации  на оборудование).
Устанавливаемое ИТ-оборудование должно подключаться к двум независимым друг от друга источникам электропитания.
Уровень резервирования всех элементов инженерных систем ЦОД должен соответствовать или превышать требования Tier III (в соответствии с классификацией Uptime Institute) к элементам инфраструктуры центров обработки данных.
В помещениях машинных залов или специализированных помещениях не должно быть размещено транзитных коммуникаций инженерных систем, не относящихся к обеспечению функционирования данных залов.
Все компоненты инженерных систем ЦОД наружного исполнения должны иметь температурный диапазон работы не выше минимальной и не ниже максимальной температуры, зафиксированной для данного региона, согласно СНиП 23-01-99 (Строительная климатология).
Электроснабжение ЦОД должно осуществляться не менее чем от двух независимых источников электроснабжения, при отключении любого из них оставшиеся должны выдерживать полную нагрузку ЦОД.
Заземление электроустановок должно быть выполнено по системе TN-S или TN-C-S.
Должна быть выполнена система функционального заземления для подключения серверного оборудования.
Система электроснабжения ЦОД должна удовлетворять действующим Правилам устройства электроустановок (ПУЭ).
Расчетная мощность на стойку определяется проектом на инженерные системы и расчетная мощность на стойку должна обеспечивать потребности установленного в стойку ИТ-оборудования, при максимальной нагрузке.
К каждой стойке должно быть обеспечено подключение двух линий электроснабжения.
Параметры напряжения системы электроснабжения ИТ-оборудования, должены соответствовать ГОСТ 32144-2013 и находиться в переделах: а) фазное напряжение 220В ±10%, б) линейное напряжение  380 В ±10%, в) диапазон частоты –  50 Гц ±0,4Гц.
Система бесперебойного электроснабжения должна быть выполнена по схеме не ниже: • Mission Critical, Business Critical - 2N, допускаются дробные схемы  (3/2N, 4/3N и т.д.) c обеспечением 2-х независимых активных лучей электроснабжения  \n• Business Operational, Office Productivity - (N+1)
Система бесперебойного электроснабжения должна быть снабжена устройством автоматического и ручного переключения на резервную линию (байпас). Должна быть обеспечена возможность перехода на байпасную линию без отключения потребителей.
Система бесперебойного электроснабжения ИТ оборудования должна обеспечивать возможность отключения любого из ИБП\\ДИБП для технического обслуживания или ремонта без отключения потребителей от бесперебойного электропитания.
Время автономной работы системы бесперебойного электроснабжения, построенной базе статических ИБП, должно быть не менее троекратного времени, необходимого для запуска ДГУ (или иного источника питания) и подачи напряжения на ИБП.
В случае применения системы бесперебойного электроснабжения, построенной на базе статических источников бесперебойного питания, не допускается размещение комплектов аккумуляторных батарей ИБП в одном помещении с ИТ-оборудованием. За заключением батарей встроенных/располагающихся в ИБП.
ЦОД должен быть обеспечен системой гарантированного электроснабжения с уровнем надежности определяемым по классификации Uptime Institute Tier Standard, не ниже, чем Tier III
Хранилище дизельного топлива системы гарантированного электроснабжения должно быть объемом, обеспечивающим работу 100% нагрузки ЦОД в течение не менее 72 (семидесяти двух) часов. Данный показатель может быть обеспечен минимальным резервным запасом топлива (обеспечивающим 100% нагрузки ЦОД в течение не менее 12 (двенадцати) часов и комплексом организационных мер, а именно: наличием договора на подвоз необходимого объема топлива, для обеспечения бесперебойной работы ДГУ в течение 72 часов.
ЦОД должен быть обеспечен специально предназначенным для него холодильным оборудованием с резервированием на уровне не ниже N+1 для любого компонента системы.
Система охлаждения должна обеспечивать в машинном зале следующие климатические параметры: - температура от 18 °до 27 °С - точки нормальной настройки температуры  22 °С - точность поддержания температуры  ±2 °С - относительная влажность от 25% до 75% - точки нормальной настройки относительной влажности  - 45% - точность поддержания относительной влажности ±5% - максимальная скорость изменения температуры в машинных залах не должна превышать значение ±5 °С в час - скорость изменения влажности не более 10% в час - перепад давления в машинных залах, по отношению к смежным помещениям, должен быть положительным
Машинные залы ЦОД должны быть оснащены: а) системой пожарной сигнализации; б) системой раннего обнаружения пожара; в) системой оповещения и управления эвакуацией; г) системой автоматики противопожарной защиты; д) системой автоматического газового пожаротушения; е) системой газоудаления; ж) индивидуальными средствами пожаротушения (углекислотными огнетушителями); з) индивидуальными средствами защиты персонала.
Остальные помещения ЦОД должны быть оснащены: а) системой пожарной сигнализации; б) системой оповещения и управления эвакуацией; в) системой автоматики противопожарной защиты; г) системой водяного пожаротушения; д) противодымной вентиляцией; е) блокировкой управления лифтами при пожаре (при наличии в ЦОД лифтов); ж) Огнетушители и гидранты по нормам РФ
Системы противопожарной безопасности должны иметь необходимые сертификаты пожарной безопасности, и соответствовать требованиям действующих норм пожарной безопасности РФ.
Здание ЦОД, должно быть не ниже III степени огнестойкости по ФЗ от 22.07.2008 N 123-ФЗ (ред. от 30.04.2021) «Технический регламент о требованиях пожарной безопасности».
ЦОД должен круглосуточно охраняться.  В зависимости от размера объекта.  \nМинимум: 1 суточный пост физической охраны на входной группе.
Доступ в помещения ЦОД и помещения машинных залов должен быть ограничен и оснащен системами охранной сигнализации, контроля и управления доступом, и системой видеоконтроля.
Компоненты физической инфраструктуры сети разделяются уровни, состоят из функциональных модулей обеспечивающих соответствующие объекты автоматизации в соответствии п. 12.2 (Таблица 1, Схема 1).
Сетевое оборудование должно обеспечивать автоматическую синхронизацию времени от доверенных источников.
Модуль должен обеспечивать сетевое взаимодействия между компонентами АС в сети ЦОД и осуществлять горизонтальное масштабирование сети.
Модуль должен обеспечивать балансировку трафика по нескольким маршрутам для повышения производительности сети.
Модуль должен использовать сетевые коммутаторы класса ЦОД. • Позиционирование оборудования вендором как коммутатор ЦОД • Пропускная способность внутренней шины должна быть в два раза выше суммарной полосы всех портов • При каскадировании необходимо чтобы аплинк был равен сумме всех интерфейсов (переподписка =1) • Два блока питания с уровнем нагрузки в штатном режиме менее 50%. • Возможность проведения настроек параметров без перезагрузки • Поддержка виртуализации на уровне 2 (VLAN) и уровне 3 (VRF)
Коэффициент переподписки сетевых компонентов модуля K=1 по пропускной способности портов.
Резервирование сетевых  компонентов модуля в рамках одного ЦОД для обеспечения устойчивости к отказам в сети без перерыва бизнес сервисов компании - 2N.
Отказоустойчивое подключение серверов к сети путем резервирования сетевых интерфейсов, подключаемых в разные сетевые устройства. \nМинимум 2 сетевых интерфейса.
Толерантность к выходу из строя внутренних компонентов оборудования ядра сети.\nМаксимальное влияние вышедшего из строя элемента - снижение производительности.
Компоненты оборудования модуля должны быть зарезервированы в РЦОД/РЦОД-ах, чтобы обеспечить 100% производительности модуля при отказе основного ЦОД.
Разграничение сетевых сегментов в ЦОД средствами межсетевого экранирования.
Активное сетевое оборудование устанавливается в отдельное помещение или шкаф/кабинет с ограничением доступа.
Управляющие интерфейсы сетевого оборудования должны размещаться в выделенных зонах СПД компании (LAN/VLAN) разграниченных при помощи МСЭ. Доступ в в выделенные зоны разрешен только Администраторам.
Сетевое оборудование должно обеспечивать настройку в соответствии с политиками безопасности: • возможность установки актуальных обновления безопасности • резервное копирование конфигураций устройств • отключение\\удаление всех неиспользуемых сервисов, протоколов и модулей • переименование (или блокировка) всех встроенныx учетных записей, за исключением учётной записи используемой для доступа через физическую консоль без права доступа посредством СПД • изменение паролей назначенных (по умолчанию) производителем • обязательное шифрование неконсольного административного доступа
Сетевое оборудование должно обеспечивать возможность использования персонифицированной  УЗ для прохождения процедур  аутентификации и авторизации доступа.
Сетевое оборудование и сетевые средствами защиты информации должны обеспечивать протоколирование событий кибербезопасности,  1. Должна как минимум обеспечиваться регистрация следующих событий КБ: • событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; • неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); • событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; • всех действий, выполненных с использованием административных привилегий. •  доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); •  инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий). 2.  Для каждого регистрируемого события КБ в журналы регистрации должны как минимум записываться следующие элементы: • тип события КБ; • источник события КБ; • дата и время возникновения события КБ; • результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); • идентификатор субъекта, предъявленный при запросе доступа; • идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; • идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
Разграничение сетевого взаимодействия между функциональными модулями сети средствами межсетевого экранирования.
Модуль должен осуществлять подключения к внешним сетям и узлам интернет и состоять из: • граничных маршрутизаторов • периметровых МСЭ • оптимизаторов трафика (опционально)
Модуль должен обеспечивать приоритезацию мультимедийного трафика и трафика АС критичным к сетевым задержками (QoS).
Модуль должен обеспечивать обязательную на выход трансляцию приватных в публичные IP адреса и наоборот (NAT).
Резервирование сетевого оборудования - минимум N+1.
Устойчивость к отказам каналов передачи данных. • При отказе одного из каналов связи, весь трафик должен быть перераспределён на остальные каналы, с соблюдением правил маршрутизации и QoS. • Количество каналов связи до каждого узла должно быть не менее двух
Георезервирование каналов передачи данных (Схема 2).
Использовать не менее двух коммуникационных узлов для обеспечения переключения каналов в случае потери одного и них и обеспечения непрерывности предоставления сервиса (Схема 2).
Использование двух независимых интернет провайдеров (ISP) (Схема 2).
Модуль должен обеспечивать защиту трафика компании от прослушивания и подмены при передаче через сеть узла связи, сеть провайдера и сеть интернет.
Обеспечивать контроль доступа внешних пользователей и подключений из внешних сетей, в т.ч. сети интернет, к опубликованным вовне ресурсам, размещенным в сегменте DMZ.
Обеспечивать защиту ресурсов сети DMZ, в том числе от DDoS атак.
Обеспечивать контроль доступа пользователей к ресурсам интернет и к партнерским ресурсам с использованием систем контроля доступа к сети интернет.
Обеспечить защиту удаленного доступа пользователей к информационным ресурсам компании с использованием средств криптографической защиты информации (remote access VPN).
Обеспечение обнаружения и предотвращения вторжений между модулем и внешними сетями (IDS/IPS), том числе с использованием модуля обнаружения вторжений на МСЭ.
Модуль должен состоять, как минимум, из одного из следующих узлов: • Центральный узел связи • Узел связи уровня доступа (ЛВС)
Возможны следующие варианты реализации подключения узлов модуля: 1.     Прямые (выделенные) каналы связи от узла связи уровня доступа до центрального узла связи (физика). 2.     Арендованная полоса в сети провайдера.  Строится на арендованных каналах связи по технологии MPLS и стыкуется с сетями провайдеров для предоставления услуги MPLS VPN от узла связи уровня доступа до центрального узла связи. 3. VPN подключения через арендованные каналы связи и интернет. Возможны следующие варианты реализации подключения узлов модуля: 1.     Прямые (выделенные) каналы связи от узла связи уровня доступа до центрального узла связи (физика). 2.     Арендованная полоса в сети провайдера.  Строится на арендованных каналах связи по технологии MPLS и стыкуется с сетями провайдеров для предоставления услуги MPLS VPN от узла связи уровня доступа до центрального узла связи. 3. VPN подключения через арендованные каналы связи и интернет.
Резервирование сетевого оборудования - минимум N+1.
Резервирование каналов передачи данных для обеспечения устойчивости к отказам. • При отказе одного из каналов связи, весь трафик должен быть перераспределён на остальные каналы, с соблюдением правил маршрутизации и QoS. • Количество каналов связи до каждого узла должно быть не менее двух.
Георезервирование каналов передачи данных (Схема 2).\nКаналы связи провайдеров не должны использовать общие участки трассы или базироваться на одних и тех же объектах операторов связи.
Компоненты оборудования модуля должны быть зарезервированы в РЦОД/РЦОД-ах, чтобы обеспечить 100% производительности модуля при отказе основного ЦОД.
Обеспечить защиту каналов связи с использованием средств криптографической защиты информации (Site-to-Site VPN).
Модуль должен осуществлять только: • обеспечение первичного подключения сотрудников к сети • доступ к групповым сетевым ресурсам
Максимальное уменьшение сегмента сети Ethernet для сокращения broadcast трафика.
Использование маршрутизированных соединений точка-точка между сетевыми устройствами.
Обозначение пользовательский сетей как конечных (не транзитных - Stub) с точки зрения протоколов динамической маршрутизации
Использование маршрутизированного доступа при отсутствии организационных ограничений требующих растянутых сегментов сети Ethernet.
Не допускается использование для построения сети оборудования не имеющего возможностей сегментирования сети.
Организация отдельных сегментов сети (LAN/VLAN) для голосового и видео трафика.
Построение сети по топологии звезда с помощью технологий стэкирования/кластеризации сетевых устройств.
Использование механизмов предотвращающих возникновение петель Ethernet на пользовательских портах.
Резервирование сетевого оборудования на уровне агрегации - минимум N+1.
Устойчивость к отказам каналов передачи данных, дублирование каналов на уровне модуля транспортной сети.
Георезервирование каналов передачи данных: • Каналы на разные узлы связи. • Каналы связи провайдеров не должны использовать общие участки трассы или базироваться на одних и тех же объектах операторов связи.
Контроль подключений конечных устройств к wired-сети: 802.1x или контроль МАС- адресов
Сетевой доступ пользователей из ЛВС Кампус к информационным ресурсам компании должен разграничиваться средствами МСЭ, в том числе с использованием функционала Identity Firewall (интеграция МСЭ со службой каталогов и разграничение доступа на основе принадлежности пользователей доменным группам).
Длина ключа шифрования для сети WiFi не менее 256 бит.
Протоколы шифрования сети WiFi: WPA2-AES или более новые версии
Наличие RADIUS сервера для обеспечения уникальных, циклично меняющихся ключей для каждого клиента
Возможность сегментации сети, включающая в себя использование нескольких SSID и VLAN, запрет трафика между пользователями внутри SSID и VLAN.
Возможность проходить процедуру автоматической аутентификации посредством сертификата: ASN.1, X.509, CMS, PKI или PKIS.  (В зависимости от уровня функционирования устройства)
Механизмы, реализующие (микро)сегментацию должны оперировать на уровне L3-L4 уровне модели OSI.
(Микро)сегментация должна обеспечивать:\n  гранулярность доступа до Сервиса.\n  уметь идентифицировать Сервис\n  отслеживать миграцию Сервиса
Экземпляры Сервисов объединяются в группы.
Доступ между Сервисами или Группами сервисов должен быть описан Правилами.
Должна быть выстроена настраиваемая Ролевая модель для управления Моделью безопасности, субъекты которой могут управлять различными объектами: Правилами, Группами, Сервисами.
Должны быть определены механизмы применения Модели безопасности к гетерогенной сетевой инфраструктуре.
Могут использоваться наложенные сети (VxLAN) поверх базовых сетей (LAN, VLAN).
Модель безопасности должна идентифицировать сервисы как в базовой сети, так и в наложенных.
Механизмы, реализующие (микро)сегментацию должны обеспечивать гранулированное применение Модели безопасности в гетерогенной сетевой инфраструктуре (VxLAN, VLAN, LAN).
Модель безопасности может организовываться в иерархии, каждый элемент иерархии может отвечать за Правила в соответствии с логическим делением сети: доступы к инфраструктурным сервисам, доступ между сервисами
Механизмы, реализующие (микро)сегментацию должны быть отделены от механизмов, оперирующих Моделью безопасности (разделение на дата-плэйн и контрол-плэйн).
Механизмы, реализующие (микро)сегментацию (дата плэйн) должны быть недоступны, в том числе (но не ограничиваясь) не должно быть возможности изменить, мониторить или вызывать иные аффекты на механизмы, реализующие (микро)сегментацию с хостов продуктовой нагрузки (пример: hostbased fw).
Управляющие интерфейсы механизмов, оперирующих Моделью безопасности не должны быть доступны из сетей продуктовой нагрузки.
Взаимодействие с управляющими интерфейсами механизмов, оперирующих Моделью безопасности (контрол-плэйн) должны осуществляться с использованием средств контроля доступа, для Администраторов решениями PAM, для технологических пользователей решениями SM.
Взаимодействие с управляющими интерфейсами механизмов, реализующих (микро)сегментацию (дата-плэйн) осуществляться с использованием средств контроля доступа, для администраторов решениями PAM, для технологических пользователей решениями SM.
Взаимодействия между управляющими механизмами и исполнительными механизмами реализующие (микро)сегментацию должны быть авторизованы.
Вычислительные системы строятся на базе commodity bare-metal серверов и виртуальной инфраструктуры.
Серверное оборудование должно базироваться на процессорах архитектуры  x86-64 ARM
Операционные системы (ОС) для обслуживания серверных приложений: • Linux • Windows - сертифицированные на используемое  оборудование
Использование аппаратного обеспечения со встроенной с функциями предсказания сбоев :оперативной памяти,дисков и других компонент,RAS-функциональностью (функциями определения и автоматической коррекции ошибок), а также встроенной функциональностью управления, мониторинга и диагностики аппаратного обеспечения.
Резервирование компонентов. Все модели серверов должны быть оснащены, как минимум: • резервными источниками питания с горячей заменой • резервными вентиляторами с горячей заменой • RAID для дисковых подсистем. Опционально – резервирование прочих компонентов.
Восстановление после сбоя. В случае выхода из строя компонентов и/или их замены система должна восстанавливаться и/или возвращаться в досбойное состояние автоматически без ручного вмешательства (например, автоматический переход на Spare и обратно).
Серверное оборудование должно быть в стоечном варианте исполнении корпуса (rack-mount) и обеспечивать установку в стандартный закрытый шкаф 19”
Средства управления аппаратным обеспечением должны иметь модули удаленного управления c возможность подключения администраторов к удалённой консоли управления посредством webбраузеров или интерфейса командной строки.
Должна обеспечиваться минимальная функциональность модуля удаленного управления: • включения/выключения питания • контроль параметров • возможность генерации NMI • возможность удаленного монтирования Flash и Folder. • загрузка с виртуального носителя • иметь функцию резервного копирования своих настроек
Средства управления аппаратным обеспечением должны обеспечивать функционал: • Онлайнового мониторинга аппаратных компонентов, в том числе для прогнозирования и отслеживания отказов -  процессоров, памяти, блоков питания, вентиляторов, дисков и VRM, изъятия компонентов, отслеживания статуса LAN и SAN интерфейсов, с отображением в статусе сервера. • Интеграцию с системой  инфраструктурного мониторинга компании.
Средства управления аппаратным обеспечением должны обеспечивать функционал экспорта данных во внешние системы инвентаризации CMDB.
Средства управления аппаратным обеспечением должны обеспечивать функционал массового развертывания обновлений firmware, установки драйверов и утилит централизованного управления.
Возможность интеграции с системой СРК, обеспечивающей создание РК на уровне приложений (агенты приложений и файловые системы).
В пределах одной зоны доступности должно быть обеспечено резервирование КТС в соответствии с уровнями указанными в Приложении 1.
Дублирование сетевых каналов связи серверов, автоматический переход на резервный канал связи в случае выхода из строя основного и переход к изначальной конфигурации после восстановления канала.
Подключение дублированных блоков питания (TACIR_1-Ч03.02.4-02) к разным вводам для обеспечения  работы при отключении половины вводов электропитания.
Резервирование КТС в разных зонах доступности должно быть обеспечено в соответствии уровнями, указанными в. Приложении 2.
Программные решения, разворачиваемые на базе серверов bare-metal, должны иметь средства обеспечения катастрофоустойчивости (репликация данных на резервный КТС и т.п.) и обеспечивать восстановление информационного сервиса при отказе серверного оборудования (см. Приложение 2).
Наличие встроенных средств (либо интеграция с внешними средствами) управления переходом на резервный ЦОД в случае недоступности основного ЦОД.
Оборудование устанавливается в отдельное помещение или шкаф/кабинет с ограничением доступа.
Управляющие интерфейсы оборудования должны размещаться в выделенных зонах корпоративной сети, доступ в которые разрешен только администраторам (см. п ТАCNW_1-Ч02.07.2-02 -  Часть 2. Стандарты и требования к инфраструктуре сетей передачи данных)
Доступ к управляющим WEB UI интерфейсам оборудования и средств управления должен осуществляться по протоколу HTTPS в соответствии со стандартом TLS 1.2 или выше.
Средства управления должны обеспечивать интеграцию со централизованной службой управления учетными записями для безопасного подключения администраторов к консоли управления.
Средства управления аппаратным обеспечением должны поддерживать гранулярную выдачу прав - гранулированные (индивидуальные) разрешения на доступ к функциям средств управления.
Средства управления аппаратным обеспечением должны иметь необходимый функционал по настройке оборудования в соответствии с политикой безопасности: • установка обновлений безопасности • резервное копирование конфигураций устройств • отключение/удаление всех неиспользуемых сервисов, протоколов и модулей • изменение или блокировка всех встроенных учетных записей • изменение стандартных паролей учетных записей установленные производителем
Средства управления аппаратным обеспечением должны обеспечивать протоколирование событий кибербезопасности. 1. Должна, как минимум, обеспечиваться регистрация следующих событий КБ: • событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; • неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; • действий, выполненных с использованием административных привилегий. • доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); • инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий). 2.  Для каждого регистрируемого события КБ в журналы регистрации должны, как минимум, записываться следующие элементы: • тип события КБ; • источник события КБ; • дата и время возникновения события КБ; • результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); • идентификатор субъекта, предъявленный при запросе доступа; • идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; • идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
Модули управления серверов должны иметь функцию автоматической перезаписи лога с сохранением удаленного лога на внешний ресурс
Серверное оборудование (bare-metal) для среды виртуализации должно соответствовать требованиям указанным в п.п. TACIR_1-Ч03.02.1-02 - TACIR_1-Ч03.02.27-02.
Платформа виртуализации должна обеспечивать сохранность данных виртуализированных сред при авариях и сбоях в системе электропитания, отказов в работе серверного и сетевого оборудования.
Платформа виртуализации должна обеспечивать возможность горизонтальной масштабируемости: пропорциональное увеличение количества вычислительных ресурсов, памяти и емкости СХД без остановки работы системы и внесения изменений в начальную архитектуру.
В качестве системы хранения данных используются программно-определяемая система хранения (SDS) или СХД поддерживаемая используемой платформа  виртуализации.
В случае использования SDS,ПО программно-определяемой СХД должно использовать локальные накопители для создания единого отказоустойчивого хранилища данных.
Должно быть обеспечено аппаратное разделение сетевых каналов связи для данных приложений/кластера виртуализации и программно-определяемой СХД (в случае использования SDS).
При использовании совместно с платформой контейнерной оркестрации, платформа виртуализации должна быть совместима и обеспечивать требования этой платформы (п.п. TACIR_1-КП-СВ-1-01 - TACIR_1-КП-СВ-5-01 ).
Платформа виртуализации должна обеспечивать синхронизацию времени от доверенных источников.
Виртуальные машины размещаются на системе виртуализации в пределах одного NUMA узла.
Применяются технологий автоматизации развертывания виртуальной инфраструктуры.
Платформа виртуализации должна иметь API для управления и конфигурирования.
Средства управления виртуальной средой должны обеспечивать возможность подключения администраторов к консоли управления посредством Webбраузеров, интерфейса командной строки или толстого клиента.
Наличие подсистемы логирования событий виртуальной инфраструктуры, обеспечивающей сбор и анализ данных всех типов журналов, создаваемых компонентами системы виртуализации, в том числе данных журналов программно-определяемой СХД, приложений, сетевого трафика, файлов конфигурации, сообщений, показателей производительности и дампов состояния компонентов и других данных.
Наличие функционала по автоматической и периодической проверке работы и настроек основных компонентов платформы виртуализации на соответствие рекомендуемым и минимально необходимыми требованиям.
Виртуальная среда должна обеспечивать передачу статуса всех своих компонент в систему мониторинга компании по протоколу SNMP и/или Syslog, либо иметь плагин к этой системе.
Интеграция с системой резервного копирования и восстановления (СРК), обеспечивающей создание РК: • на уровне снимков виртуальных машин (интеграция для получения снимков ВМ) • на уровне приложений (агенты приложений и файловые системы).
Наличие возможности создания гибких политик резервного копирования и их исполнения (с внешним планировщиком запуска заданий РК). Возможность привязки ВМ к политике РК и автоматизированного поддержания наличия заданного политиками набора РК.
Наличие средств автоматизация восстановления ВМ (восстановление ВМ из шаблона и дальнейшее восстановление из РК).
Должны быть развернуты и настроены отказоустойчивые кластеры высокой доступности в рамках ЦОД обеспечивающие автоматический перезапуск виртуальных машин на резервных вычислительных мощностях в случае выхода из строя аппаратного сервера, возможность выполнения «живой» миграции ВМ между узлами виртуализации и автоматической балансировки нагрузки между узлами кластера.
Наличие вычислительных мощностей кластера, позволяющих обеспечить непрерывную работу платформы виртуализации в полном объеме, включая функционал высокой доступности при недоступности двух вычислительных узлов.
Поддержка решения, обеспечивающего катастрофоустойчивость (дублирование КТС виртуализации в резервной зоне/зонах, и репликацию данных на резервный КТС) в соответствии с уровнями указанными в Приложении 2.
Управляющие интерфейсы платформы виртуализации должны размещаться в выделенных зонах корпоративной сети, доступ в которые разрешен только администраторам (см. п ТАCNW_1-Ч02.07.2-02 -  Часть 2. Стандарты и требования к инфраструктуре сетей передачи данных).
Доступ к управляющим WEB UI платформы виртуализации должен осуществляться по протоколу HTTPS в соответствии со стандартом TLS 1.2 или выше.
В UI платформы виртуализации должен быть реализован функционал, контролирующий соответствие идентификатора сессии IP-адресу и типу браузера (user agent) авторизованного пользователя.
В UI Платформы для идентификаторов сессии, хранящихся в cookie, требуется указание атрибута path и флагов HttpOnly, Secure.Запрещается использование постоянных (persistent) cookie.
Все взаимодействия (вызовы API) между подсистемами платформы виртуализации, а также с внешними системами, должны выполняться только после успешной взаимной аутентификации участников, в т.ч. подсистем аудита и мониторинга
В UI , CLI или API Платформы виртуализации должен быть реализован функционал: • обеспечивающий работу  аутентифицированных и авторизованных в UI и/или CLI пользователей только в рамках установленной активной сессии • принудительного автоматического завершения сессии пользователя после истечения времени неактивности. Период неактивности должен быть настраиваемым.
При любой успешной аутентификации и/или повторной аутентификации пользователя в UI , CLI или API платформы виртуализации должна создаваться новая сессия с новым идентификатором (session id). Повторное использование недействительного идентификатора сессии (session id) запрещено.
Настройка TLS должна включать в себя обязательную шифрование с использованием криптостойких алгоритмов.
При межсервисном взаимодействии по протоколу TLS, для аутентификации должна использовать индивидуальный SSL-сертификат.
Используемые SSL сертификаты, должны быть выпущены доверенным УЦ. Использование самоподписанных и wildcard-сертификатов не допускается.
Должен быть определен перечень критичных операций, осуществляемых администратором, требующих подтверждения второй рукой и операции администраторов платформы виртуализации, способные нарушить работу бизнес процессов, должны осуществляться с согласованием второй руки.
На серверах гипервизоров разрешается установка ОС, прикладного и системного ПО доверенных репозиториев (источников).
Должна быть реализована антивирусная защита на уровне гипервизоров.
Выполнение штатных административных задач в рамках ВМ не должно требовать предоставления администратору ВМ расширенных прав, равнозначных правам администраторов системы виртуализации.
Наличие аутентификационных данных, необходимых для доступа к ВМ и системе виртуализации в конфигурационных файлах должно быть исключено.
Запрещен доступ с гостевых ВМ к инфраструктуре хостов платформы виртуализации (сетевые интерфейсы, блочные устройства, ОП и пр.).
Запрещена возможность экспорта конфиденциальных данных с гостевых ВМ на хосты платформы.
Используется канальное шифрование для организации доступа к конфигурации ВМ и файлов с образами ВМ на жестких дисках
Средства управления системой виртуализации должны обеспечивать возможность интеграция с единой службой управления учетными записями для безопасного подключения администраторов к консоли управления.
Ролевая модель доступов к сервисам платформы виртуализации должна соответствовать принципу наименьших привилегий.
Не должно быть совмещения ролей администратора платформы виртуализации с любыми другими ролями, а также должны быть исключены операции наследования прав.
Должна быть исключена возможность удаления информации о пользователях, зарегистрированных в системе, в том числе заблокированных.
Администраторы платформы виртуализации должны использовать свои персонифицированные учетные записи.
Использование технологических учетных записей вне технологических процессов запрещено.
В системе виртуализации секреты не должны быть видны в открытом виде: в лог-файлах, именах запущенных процессов, переменных окружения и т.п.
У администраторов платформы виртуализации не должно быть прав, позволяющих изменять бизнес-логику приложений, запущенных в гостевых системах.
Средства управления платформой виртуализации должны иметь необходимый функционал по настройке и настройку системы в соответствии с политикой безопасности: • установка обновлений безопасности • резервное копирование конфигураций устройств • отключение/удаление всех неиспользуемых сервисов, протоколов и модулей • блокировки использования любых API и интерфейсов систем виртуализации, входящих в состав вендорского продукта и незадействованных в процессе работы инфраструктурных сервисов • запрещение использования протокола NTLM версий 1 и 2 для аутентификации прикладных и инфраструктурных сервисов и использования протокола LDAP для аутентификации сервисов без шифрования передаваемых данных • изменение стандартных паролей учетных записей установленные производителем
Средства управления платформой виртуализации должны обеспечивать протоколирование событий кибербезопасности: 1. Как минимум регистрация следующих событий КБ: • событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; • неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); • событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; • действий, выполненных с использованием административных привилегий. •  доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); • инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий); • технологические операции; • создание и удаление объектов системного уровня. 2.  Для каждого регистрируемого события КБ в журналы регистрации должны как минимум записываться следующие элементы: • тип события КБ; • источник события КБ; • дата и время возникновения события КБ; • результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); • идентификатор субъекта, предъявленный при запросе доступа; • идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; • идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
В платформе виртуализации должна быть реализована передача событий аудита в централизованный сервис аудита, с поддержкой защищенного авторизованного соединения и исключена возможность отключения передачи событий в централизованный сервис аудита.
Не допускается передача в событиях аудита конфиденциальных данных.
Возможность доступа к данным аудита должна предоставляться только уполномоченным пользователям и только через прикладной уровень.
Архитектура  платформы контейнерной оркестрации должны соответствовать архитектуре представленной на Схеме 1  и включать в себя все компоненты обязательные для соответствующего класса критичности АС.
Аппаратная платформа должны соответствовать требованиям указанным в п.п. TACIR_1-Ч03.01.1-01 - TACIR_1-Ч03.02.25-02.
Платформа виртуализации должны соответствовать требованиям указанным в в п.п. TACIR_1-Ч03.03.2-01 - TACIR_1-Ч03.03.30-03.
Переподписка на уровне кластера виртуализации должна быть с коэффициентом не более 2 (двух).
Для ВМ нод кластера платформы контейнерной оркестрации запрещено резервирование ресурсов по CPU\\Memory в ресурсных пулах.
Поддержка онлайн миграции ВМ нод платформы контейнерной оркестрации между хостами гипервизоров в кластересистемы платформы виртуализации (DRS, балансировка нагрузки) для нивелирования переподписки по ЦПУ.
Поддержка миграция файлов дисков ВМ нод платформы контейнерной оркестрации между датасторами для нивелирования переподписки по дискам (Storage DRS).
Кластер платформы контейнерной оркестрации должен состоять из набора машин (узлов) и развёртывается на нескольких узлах. • мастер узлы (master nodes -  минимум 3 узла • рабочие узлы (worker nodes) - минимум 2 узла
Только один мастер узел активен и контролирует весь набор рабочих узлов кластера. Один из неактивных мастер узлов берет лидерство в случае, если активный узел утерян.
Платформа контейнерной оркестрации должна иметь в резервных зонах доступности кластер/кластеры обеспечивающие 100% производительности платформы при потере основной зоны.
Кластер (Control Plane и Data Plane кластера) разворачиваются/размещается в пределах только одной зоны доступности, за исключением PaaS решений.
Встраиваемые компоненты устанавливаются в отдельные namespace для каждого компонента, операторы находятся в выделенных namespace.
Платформа контейнерной оркестрации должна поддерживать механизмы автомасштабирования при изменении нагрузок на приложения АС.
Механизмы горизонтального автомасштабирования платформы контейнеризации при изменении нагрузок на приложения АС должны быть настроены и активированы.
Система мониторинга собирает и предоставляет информацию по фактической утилизации ресурсов.
Журналы платформы контейнерной оркестрации должны храниться во внешней по отношению к платформе контейнеризации системе сбора и анализа журналов.
В платформе контейнерной оркестрации имеются механизмы и активированы настройки лимитов и запросов на ресурсы CPU/RAM.
Платформа контейнеризации должна предоставлять возможность ограничения доступа в сеть интернет на уровне ноды кластера и специализированного шлюза кибербезопасности.       Запрещается прямая публикация кластеров контейнеризации в сеть интернет.
Все компоненты кластеров контейнеризации должны обеспечивать синхронизацию времени с централизованным корпоративным сервером времени
Каждый кластер платформы контейнерной оркестрации должен размещаться только в одной из зон сетевой безопасности.
Каждый кластер платформы контейнерной оркестрации должен размещаться только в одном сегменте сети.
Инфраструктурные сервисы должны размещаться на выделенных нодах кластера.
Управление жизненным циклом секретов платформы контейнерной оркестрации должно быть организовано в системе управления секретами.
Платформа контейнеризации должна обеспечивать интеграцию с корпоративным удостоверяющим центром для выпуска сертификатов, обеспечивающих защиту интерфейсов взаимодействия. Должно обеспечиваться шифрование на уровне сессии с использованием протокола TLS версии 1.2 и выше.
Привилегированный доступ (например: администраторы, DevOps и т.д.) к хостовым ОС и интерфейсам управления платформы контейнерной оркестрации должен осуществляться посредством системы контроля привилегированного доступа.
Для аутентификации учетных записей необходимо использовать внешнюю, по отношению к платформе систему аутентификации.
Управление конфигурациями платформы контейнерной оркестрации должно осуществляться через корпоративную систему управления конфигурациями.
Платформа контейнерной оркестрации должна обеспечивать подключение CNI плагинов и иных инструментов для настройки правил микросегментации.
Платформа контейнерной оркестрации запрещает контейнерным приложениям, развернутым в платформе, работать вне виртуальной сети (SDN) и/или иметь прямой доступ к хостовой сети.
Запрещено анонимное подключение к API платформы контейнерной оркестрации.
Платформа контейнерной оркестрации должна запрещать использование незащищенных портов при взаимодействии c API компонентов платформы.
Взаимодействие с API платформы контейнерной оркестрации должно осуществляться через шлюзы  безопасности или решения с аналогичным функционалом.
Управление правами и доступами учетных записей к namespace должно осуществляться через систему управления учетными записями.
Запрещено использовать пространство имен по умолчанию (default).
Платформа контейнерной оркестрации должна иметь возможность запрета использования решений, требующих персистентного хранения данных на стороне платформы контейнеризации.
Платформа контейнерной оркестрации должна обеспечивать возможность настройки и контроля прав (к интерфейсу управления платформы) и политик доступа подов (сети, файловой системе и т.д.).
Платформа контейнерной оркестрации должна обеспечивать возможность управления политиками или стандартами безопасности для Pod
Компоненты платформы контейнерной оркестрации  должны обеспечивать протоколирование событий кибербезопасности.       Состав и содержание информации в событиях кибербезопасности должен определяться подразделением выполняющим функции кибербезопасности в компании.
Используемая подсистема хранения событий аудита должна быть расположена вне платформы контейнерной оркестрации.
Передача событий в подсистему аудита должна быть реализована с использованием одной из согласованных схем для передачи. Запрещено передавать события аудита совместно с данными выполняемых операций, в том числе с использованием общего транспорта.
Системы хранения данных должны быть следующих типов: - Программно-определяемая СХД(Software-Defined Storage – SDS); - СХД традиционной аппаратной компоновки; - Объектной системой хранения данных.
СХД должна поддерживать горизонтальное масштабирование (пропорциональное увеличение емкости и производительности СХД без остановки работы системы).
Все операции ввода-вывода на запись должны обрабатываться через кэш на базе энергонезависимой памяти, при этом иметь возможность обеспечивать сохранность данность данных при сбое сервера (для SDS), кеширующего устройства или устройства хранения.
В СХД традиционной аппаратной компоновки должен присутствовать функционал (в том числе наличие лицензий) оптимизации данных по объему (компрессии, дедупликации).
СХД должна быть сконфигурирована с применением технологий защиты данных (например RAID, Erasure coding и др.) в случае физического сбоя компонентов.
В СХД традиционной аппаратной компоновки и SDS для хранения оперативных данных должны быть использованы флеш-накопители.
В СХД должна быть настроена синхронизация времени с использованием  корпоративных централизованных источников.
Развертывание, управление и мониторинг СХД должны осуществляться через интерфейс или командную строку модулей управления (management module) СХД или средства управления.
В СХД традиционной аппаратной компоновки и SDS должен присутствовать функционал создания snapshots и clones без прерывания сервиса.
Наличие резервных компонентов для обеспечения автоматического восстановления работы СХД, в случае выхода из строя аппаратной части, и обеспечения непрерывной работы при проведении регламентных работ (тех. обслуживание, ремонт и т.д.): - дублирование контролеров (минимум 2); - дополнительных дисков (spare disks); - не менее 2 блоков питания подключенных к разным вводам электропитания (к разным автоматам); - случае использования SDS, наличие запасных мощностей позволяющих обеспечить доступность данных в случае выхода из строя двух узлов хранения (FTT>=2).
Подключение дисковых ресурсов производится через разные плечи (SAN, LAN) с учетом дублирования путей на всем тракте (СХД-хост).
Интерфейсы управляющих (management) модулей СХД подключены к разным сетевым коммутаторам.
В СХД традиционной аппаратной компоновки должен присутствовать  функционал контроля/мониторинга для определения пред-сбойного состояния носителей.
СХД должны быть зарезервированы в разных зонах доступности, чтобы обеспечить 100% производительности и емкости дискового пространства.
Оборудование должно быть установлено в специально выделенном помещении с ограничением физического доступа.
Должен быть обеспечен зонинг в сетях передачи данных SAN, LAN для изоляции доступа к данным по хостам.
Управляющие интерфейсы контроллеров СХД должны быть подключены в выделенную зону корпоративной сети(см. п ТАCNW_1-Ч02.07.2-03 -  Часть 2. Требования к инфраструктуре сетей передачи данных).
Средства управления системой хранения данных должны иметь необходимый функционал по настройке системы в соответствии с политикой безопасности: - установка обновлений безопасности; - резервное копирование конфигураций устройств; - отключение/удаление всех неиспользуемых сервисов, протоколов и модулей; - изменение паролей назначенных (по умолчанию) производителем; - обязательное шифрование неконсольного административного доступа (TLS не ниже v1.2).
Средства управления СХД должны поддерживать интеграцию с централизованной службой управления учетными записями.
Средства управления СХД или централизованная служба управления учетными записями должны :\n1.как минимум обеспечивать регистрацию следующих событий: - событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; - неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); -  событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; - действий, выполненных с использованием административных привилегий; - доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); - инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий).\n2. Для каждого регистрируемого события КБ в журналы регистрации должны как минимум записываться следующие элементы: - тип события КБ; - источник события КБ; - дата и время возникновения события КБ; - результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); - идентификатор субъекта, предъявленный при запросе доступа; - идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; - идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
СХД должна поддерживать выгрузку событий аудита в централизованную систему  мониторинга КБ для анализа событий кибербезопасности.
Система резервного копирования данных строится на базе дисковых массивов/дисковых библиотек для обеспечения оперативного резервного копирования и восстановления данных.
Запрещается размещать РК на том же СХД или ресурсах хранения данных, где расположены исходные данные с которых делается РК.
В СРК должен присутствовать функционал (в том числе наличие лицензий) оптимизации данных по объему (компрессии, дедупликации).
Политики резервного копирования должны обеспечивать репликацию/перемещение резервных копий в другую зону доступности, другой ЦОД.
Политики резервного копирования должен обеспечивать полное восстановление данных на время последней сессии резервного копирования.
Политики резервного копирования/восстановления должны включать в себя проведение периодических проверок восстановления данных из резервных копий не менее 1-ого раза в полгода.
При расположении инфраструктуры на ресурсах облачного провайдера услуга СРК может быть приобретена как сервис (PaaS) c условием выполнения требований этого стандарта.
Управление СРК должно обеспечиваться из консоли системы управления СРК.
Системы управления СРК должны обеспечивать разделение ролей по управлению политиками резервного копирования.
Для облачного сервиса BaaS, управление выделенными ресурсами СРК облачного провайдера должно обеспечиваться из консоли централизованного управления ресурсами в облаке.
СРК должна обеспечивать передачу данных мониторинга СРК в систему инфраструктурного мониторинга (SNMP, Syslog или с использованием агента).
Оборудование должно быть установлено в специально выделенном помещении с ограничением физического доступа.
Резервные копии должны быть защищены от физического и логического воздействия. Способы и средства защиты определяются подразделением ИБ Компании.
Резервные копии долговременного архивного хранения должны быть защищены от удаления.       Время хранения определяется компанией.
Управляющие интерфейсы СРК должны быть подключены в выделенную зону корпоративной сети (см. п ТАCNW_1-Ч02.07.2-03 -  Часть 2. Требования к инфраструктуре сетей передачи данных).
Системы управления СРК должны иметь необходимый функционал по настройке системы в соответствии с политикой безопасности: - установка обновлений безопасности; - резервное копирование конфигураций устройств; - отключение/удаление всех неиспользуемых сервисов, протоколов и модулей; - изменение паролей назначенных (по умолчанию) производителем; - обязательное шифрование неконсольного административного доступа (TLS не ниже v1.2).
Средства управления СРК должны поддерживать интеграцию с централизованной службой управления учетными записями.
Средства управления СРК или централизованная служба управления учетными записями должны :\n1. Как минимум обеспечиваться регистрация следующих событий: - событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; - неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); - событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; - всех действий, выполненных с использованием административных привилегий; - доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); - инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий).\n2. Для каждого регистрируемого события КБ в журналы регистрации должны как минимум записываться следующие элементы: - тип события КБ; - источник события КБ; - дата и время возникновения события КБ; - результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); - идентификатор субъекта, предъявленный при запросе доступа; - идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; - идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
Средства обеспечивающие функционал репликации/перемещения РК должны обеспечивать защиту данных, целостность при передаче и защиту от утечек.
СРК должна поддерживать выгрузку событий аудита в централизованную систему  мониторинга КБ для анализа событий кибербезопасности.
АРМ должно быть одним из следующих типов: • Стационарное АРМ • Переносное АРМ • Виртуальное АРМ • Тонкий клиент
Операционные системы разрешенные для установки на АРМ: • Windows  • macOS • Linux Используемые версии ОС должны быть на поддержке у производителя.
Запрещена установка или запуск на АРМ дополнительных экземпляров ОС.
На АРМ всех типов (см. п. ТАCWS_1-Ч05.01.1-02) должен быть подготовлен и установлен Базовый программный образ АРМ, включающий набор Базового ПО АРМ для соответствующего типа операционной системы (Таблица 1).
В зависимости от бизнеса компании, должно использоваться локальное ПО (если компания в России, то Российское, или OpenSource ПО) для минимизации рисков попасть под возможные санкции.
Управление АРМ должно осуществляется централизованной/ми системами управления АРМ.
Система управления АРМ должна обеспечивать: плановое обновление ОС и ПО АРМ, установку критических обновлений, изменению политик безопасности, обновление антивирусных баз.
Развернута система для сбора информации о ПО установленном на АРМ.
Учёт количества имеющихся и использованных лицензий ПО АРМ должен производится в системе управления АРМ или в другой предназначенной для этого системе.
На АРМ должен быть ограничен доступ пользователей к:       BIOS (при наличии) загрузчику ОС и/или recovery-режиму Блокирован режим безопасного восстановления.
Разделы жесткого диска переносных АРМ должны быть зашифрованы.
При удаленном подключении к сети компании должен быть реализован механизм идентификации и аутентификации пользователей и АРМ
Для пользовательской учетной записи должна быть запрещена возможность запуска и останова сервисов или процессов запущенных под технологическими или иными пользовательскими УЗ.
Для пользовательских УЗ запрещены права локального администратора, за исключением случаев согласованных с подразделением выполняющем функцию контроля Кибер Безопасности Компании
Базовый программный образ АРМ должен быть подготовлен в соответствии с политикой безопасности.\n\n   - установлены все актуальные обновления безопасности\n   - отключены\\удалены все неиспользуемые сервисы, протоколы и модули\n   - блокировано автоматическое монтирование носителей\n   - изменены или заблокированы все встроенные учетные записи, включая административные\n   - изменены пароли назначенные (по умолчанию) производителем\n   - пароли встроенного администратора рандомизируются (laps)
ПО АРМ и системы управления АРМ должны обеспечивать протоколирование и контроль событий кибербезопасности, генерируемых АРМ и системами управления АРМ. 1. Должна как минимум обеспечиваться регистрация следующих событий КБ: • событий входа и выхода субъектов доступа, обладающих в том числе и административными полномочиями; • неудачных попыток логического доступа (неправильный ввод пароля, превышение полномочий и т.п.); • событий использования механизмов идентификации и аутентификации (создание/удаление учетных записей, изменение привилегий учетных записей и т.п.), включая неудачные попытки использования данных механизмов; • всех действий, выполненных с использованием административных привилегий. •  доступа к журналам регистрации событий КБ (к записям о событиях КБ в системе); •  инициализации журналов протоколирования событий КБ (события начала/прекращения регистрации событий в журнале, очистка журнала регистрации событий). • сетевых соединений. 2.  Для каждого регистрируемого события КБ в журналы регистрации должны как минимум записываться следующие элементы: • тип события КБ; • источник события КБ; • дата и время возникновения события КБ; • результат действий субъекта (например, попытки входа): успешные или неуспешные (несанкционированные); • идентификатор субъекта, предъявленный при запросе доступа; • идентификатор (адрес) системного компонента (компьютера), используемого для доступа к системе; • идентификатор (адрес) или название данных, системного компонента или ресурса, на которые повлияло указанное событие.
Антивирусное программное обеспечение входящее в набор Базового ПО АРМ должно быть обеспечено подпиской на регулярное обновление сигнатур. В соответствии с выходом сигнатур поставщика антивирусного ПО.
АРМ работников, обладающих административными правами (на вычислительных системах, коммуникационном оборудовании, СХД, СРК) размещаются в отдельных сетевых сегментах без доступа к сети Интернет.
Обеспечена обязательная аутентификация доступа администратора к АРМ и системам управления АРМ. Назначение администраторов (тех. поддержки) оформляется распоряжением Каждый администратор использует персонифицированную УЗ для прохождения процедур идентификации, аутентификации и авторизации на каждом АРМ
На АРМ должна действовать политика на сложность пароля: более 12 символов включая: большие, маленькие буквы, цифры, спецсимволы.
Должна действовать политика необходимости регулярной смены пароля: не реже 1-го раза в 80 дней.
На АРМ должна действовать политика автоматической блокировки экрана (пользовательской сессии). Время неактивности пользователя не более 15 мин. Для возобновления пользовательской сессии требуется ввод пароля.
Должна обеспечиваться блокировка учетной записи пользователя после 5 неудачных попыток ввода пароля.
Должны быть реализованы политики ограничения на запуск и контроля использования  ПО.
Необходимо обеспечить контроль и выявление нелегитимно установленного ПО на АРМ
Должен обеспечиваться запрет пользователям производить загрузку АРМ с внешних носителей информации (USB-накопителей, оптических дисков, внешних жестких дисков и др.)
Разрешается подключать к АРМ только USB-HID устройства и док-станции, которые согласованы подразделением компании выполняющем функцию КиберБезопасности.
Разрешено подключение к корпоративным АРМ  переносных устройств: телефонов, смартфонов, планшетных компьютеров, usb, адаптеров беспроводных (радио) интерфейсов, модемов и прочего оборудования, позволяющего осуществлять подключение к публичным сетям (в т.ч. Интернет), только входящих в список устройств согласованных с подразделением компании выполняющем функцию КиберБезопасности.
Должен быть обеспечен запрет на подключение внешних носителей информации к АРМ компании.
Должен быть обеспечен запрет осуществления одновременного подключения по проводным и беспроводным интерфейсам и/или по двум сетевым портам при подключении к СПД компании.
Обязательное подключение к системе инфраструктурного мониторинга ИТ инфраструктуры обеспечивающей работу АС компании
Обязательное подключение к системе прикладного мониторинга для всех прикладных компонентов в составе АС компании.
Система мониторинга является объектом управления в ИТ-процессах и должна быть зарегистрирована как АС в  реестре АС компании или аналогичном документе с соответствующим классом критичности.
СМ должна включать в состав средства сбора данных мониторинга (агенты, коллекторы, специальные API).
СМ должна включать в состав функции визуализации данных мониторинга и/или специально разработанный API.
СМ должна содержать функции управления событиями мониторинга
Обязательное проведение процедуры нагрузочного тестирования для оценки влияния СМ на производительность АС.
Наличие механизмов обеспечения непрерывности в соответствии с классами критичности систем мониторинга: Business Critical и выше: High Availability, Disaster Recovery, Для остальных:High Availability )
СМ должна иметь возможно передавать периодический сигнал Heart Beat (Liveness / Readiness )
Запрещается размещать серверные компоненты СМ на одном КТС с объектом мониторинга (за исключением агентов, sidecar'ов, клиентских модулей и т.п. мониторинга).
Данные мониторинга хранятся отдельно от объектов мониторинга.
Должно быть обеспечено надёжное хранение собранных данных мониторинга и результатов их обработки: • данные мониторинга хранятся  в соответствии с требованиями к хранению данных для соответствующих классов критичности АС • соблюдены требования по кибербезопасности (ТАCMN_1- Ч06.05.1-01 -  ТАCMN_1- Ч06.05.3-0).
Должна соблюдаться глубина хранения данных мониторинга.Требования приведены в соответствующих разделах текущего документа  п.п. ТАCMN_1-Ч06.02.4-01 ТАCMN_1-Ч06.02.6-01 ТАCMN_1-Ч06.04.4-02
Системы мониторинга должны иметь возможность передавать данные мониторинга в следующем составе: • Наименование метрики  • Дата/время • Группа метрики (Приложение 1), • Значение метрики • Единица измерения (опционально)  • Оценка порогового значения (Приложение 2)
Для команий входящих в Экосистему обязательна интеграция с объединяющим элементом SberRadar. см. СБОРНИК СТАНДАРТОВ Процессы управления ИТ-сервисами (ITSM-процессы) Группы и Экосистемы ПАО Сбербанк. ЧАСТЬ 9. Стандарт и требования по процессу Управления технологическими событиями и мониторингом Группы и Экосистемы ПАО Сбербанк
Обязательное подключение к синтетическому мониторингу  пользовательского Web-интерфейса и используемыми публичными API раз в минуту с  заданными пороговыми значениями.
Все эксплуатируемые ИТ инфраструктурные объекты разбиваются на группы (с точки зрения единого подхода к управлению/сопровождению такими объектами).
Для каждой группы разрабатывается базовый набор метрик (ведется в формате реестра), который является обязательным для мониторинга объекта из этой группы и одинаковый для всех объектов из группы.  • Формат реестра базовых наборов инфраструктурных метрик приведен в Приложении 3.
Для базового набора должны быть определены время хранения собранных данных и частота сбора (в зависимости от критичности).
Минимальная длительность хранения: • исходных данных - 2 недели  • часовых агрегированныхданных  метрик - 1 год + 2 месяца* • Обработанных логов/журналов - 1 год + 2 месяца *
Частота сбора данных с инфраструктурных объектов: • с классом критичности Mission Critical - не реже, чем раз в 1 мин; • с классом критичности Business Critical - не реже, чем раз в 5 мин; • для остальных - не реже, чем раз в 10 мин *
Реализация/подключение прикладного мониторинга является необходимым условием для внедрения АС (и доработок АС), обеспечивающих бизнес сервис и услуги, в промышленную эксплуатацию.
Необходимо определить базовый набор прикладных метрик (операционные, сервиса, приложения, окружения приложения).
Если сервис или услуга оказывается по нескольким направлениям/каналам/платформам – по каждой комбинации должны быть свой набор базовых метрик.
Для базового набора должны быть определены время хранения собранных данных и частота сбора (в зависимости от критичности).
Минимальная длительность хранения прикладных метрик в общем случае: • исходных данных - 1 месяц; • часовых агрегированных данных - 1 год + 2 месяца *
Частота сбора по умолчанию: • для АС с классом критичности Mission Critical - не реже, чем раз в 1 мин;  • для АС с классом критичности Business Critical - не реже, чем раз в 5 мин; • для остальных АС - не реже, чем раз в 10 мин *
Запись в журналы (логирование) должна выполняться асинхронно и не оказывать влияния на выполнение бизнес-функции приложения.
Долговременное хранение журналов должно быть организовано отдельно от объекта журналирования.
При реализации журналирования должны быть использованы стандартные открытые библиотеки или фреймворки для возможности портирования и дальнейшей обработки.
Журналы должны быть читабельные и их просмотр должен быть возможен без дополнительных плагинов или агентов в текстовом редакторе и/или web-browser.
Минимальная длительность хранения составляет: • оперативных исходных логов - 2 недели • архивное хранение обработанных логов - не менее 45 дней *
Для сервисов и услуг должен быть настроен трейсинг исполнения.
Должны быть использованы стандартные открытые библиотеки или фреймворки  механизмов распределённой трассировки и инструментирования вызовов (например OpenTelemetry).
Трейс должен обеспечивать возможность определения конкретных мест сбоя и снижения производительности в приложении, фреймворке, библиотеке, промежуточном ПО на всём пути выполнения запроса.
Глубина хранения трейсов - не менее 1 недели. *
Прямой доступ к хранилищу данных мониторинга минуя средства визуализации и/или документированный разработчиком СМ API запрещен.
Средства для ведения журналов и внесенная в них информация должны быть защищены от несанкционированного доступа и изменения.
Должны быть зафиксированы действия системных администраторов и операторов, журналы должны быть защищены от изменения или очистки администратором/оператором
Обработка данных мониторинга должна осуществляться в соответствии с присвоенной категорией конфиденциальности данных.
Объекты типа Шлюз безопасности, устанавливаемые на сервера с одним сетевым интерфейсом, должны размещаться на стороне защищаемой сети в буферном сегменте.\nВ облаках Sbercloud, публичных облаках шлюзы безопасности с двумя (и более) сетевыми интерфейсами не используются.
Объекты типа Шлюз безопасности, устанавливаемые на сервера  с двумя сетевыми интерфейсами, должны размещаться в шлюзовой сети в периметре сети компании в соответствии со следующими требованиями: • внешний интерфейс шлюза безопасности (интерфейс, получающий трафик до проверки по схеме и фильтрации трафика)  должен размещаться: • В Буферном сегменте - DMZ  • внутренний интерфейс шлюза безопасности (интерфейс, отправляющий трафик после его терминирования на шлюзе безопасности и по результатам его фильтрации) должен размещаться: • В Сегменте обработки данных компании  (только для физически разделенных сетей)\nВ облаках Sbercloud, публичных облаках шлюзы безопасности с двумя (и более) сетевыми интерфейсами не используются.
Запрещается установка объектов, отличных от шлюзов безопасности, описанных в требовании TACNW_1-L-2-01, на сервера с двумя сетевыми интерфейсами, включаемыми в различные сетевые сегменты
Объекты типа Презентационный слой размещаются в соответствии со следующими требованиями: • при наличии взаимодействия с объектами или пользователями во внешних сетях (сеть Интернет, внешние организации по выделенным каналам связи) - только в буферном сегменте DMZ (буферных сегментах сетей внешнего периметра)  • при наличии взаимодействий с объектами или пользователями только в рамках одного сегмента (обработки данных) - в соответствующем сегменте обработки данных
Объекты типа Прокси размещаются аналогично объектам типа Презентационный слой (TACNW_1-L-4-01).
Объекты типов Бизнес-логика и Основное хранилище данных, обрабатывающие Конфиденциальные данные (конфиденциальную информацию), размещаются в соответствии со следующими требованиями: • хранение данных в незашифрованном виде - только сегменте обработки данных  внутренней (физически не возможно попасть в интернет) сети компании, а также в сегментах обработки данных облачных инфраструктур (Sbercloud, Публичные облака) при условии полного обеспечения требований регуляторов к защите конфиденциальной информации (ГИС, ПДн, ОКИИ, PCIDSS, Банковская тайна); • хранение данных в зашифрованном виде - любые сегменты обработки данных (компании, Cloud, публичные облака)
Объекты типа Бизнес-логика и Основное хранилище данных, обрабатывающие информацию не относящуюся к Конфиденциальным данные (конфиденциальной информации) и открытые данные, могут размещаться в любых сегментах обработки данных
Объекты типа Клиентская часть размещаются в сегментах обработки данных, в сети модуля ЛВС компании либо во внешних сетях (в т.ч. Интернет, при условии полного обеспечения требований регуляторов к защите конфиденциальной информации (ГИС, ПДн, ОКИИ, PCIDSS, Банковская тайна))
Объекты типа Обеспечивающие сервисы размещаются в соответствии со следующими требованиями:  • в сегментах обработки данных и Буферных сегментах для АС, размещаемых в периметре сети компании; • в Сервисных сегментах для АС, размещаемых в облачных инфраструктурах (Cloud, публичные облака)
Система должна быть реализована в компонентной архитектуре, а именно должна состоять из слабо связанных компонентов, взаимодействующих друг с другом с помощью универсальных (не зависящих от среды разработки и исполнения) интеграционных интерфейсов (API).
В системе необходимо обеспечить разделение презентационной логики, бизнес-логики и логики хранения данных
Запрещена реализация бизнес-логики на уровне подсистемы хранения данных, в том числе запрещена реализация бизнес-логики в виде хранимых процедур БД.
Для систем класса OLTP запрещено выполнение OLAP-задач и генерация отчетности на СУБД промышленного контура.
Настройка системы должна осуществляться путем изменения конфигурационных параметров, без изменения основной кодовой базы. Хардкод конфигурационных параметров, приводящий к повторной сборке и разворачиванию системы, запрещен. При этом запрещается реализация возможности отключения настройками механизмов аутентификации, авторизации и аудита.
Должна быть обеспечена возможность горизонтального (scale-out) масштабирования решения/компонентов решения.
Решение должно быть как минимум cloud-ready в терминах Части 8 настоящего Сборника.
Серверные исполняемые компоненты решения должны исполняться на системном ПО (СУБД, сервер приложений, ОС), соответствующим требованию TACAP_2-Ч07.ПА-10-03
Прямые запросы к системе хранения данных из слоев решения, отличных от слоя доступа к данным, запрещены.
В целях импортозамещения, решение должно отвечать как минимум одному критерию из списка: ·решение должно быть реализовано на стеке технологий Open Source и позволять его свободное использование и/или модификацию в коммерческих целях компании ·решение должно быть включено в реестр решений, рекомендованных регулятором страны регистрации компании. Например, для российских компаний таким реестром является «Единый реестр российских программ для электронных вычислительных машин и баз данных» Министерства Связи РФ (https://reestr.minsvyaz.ru/reestr/) ·решение должно быть разработано и поддерживаться юридическими лицами страны регистрации компании ·разработчик должен произвести условное депонирование (эскроу) программного обеспечения решения, инструкций по компиляции и сборке кода, описания нестандартных параметров и уникальных особенностей, спецификаций на API, пользовательских настроек, диагностических тестов и сторонних библиотек
Решение должно иметь механизмы обработки ошибок, с возможностью предоставлять пользователям и администраторам информацию об ошибках, достаточную для идентификации и разрешения возникших проблем
Необходима функциональность журналирования событий аудита в системе, локально или в централизованном хранилище событий аудита. Срок хранения журналов должен определяться внутренними нормативными документами компании и требованиями регуляторов
Информация в журнале аудита должна представляться в структурированном виде в терминах прикладной области. Содержимое, объем и полноту данных в журнале аудита определяет подразделение компании, исполняющее функции кибербезопасности.
Необходимо обеспечить возможность мониторинга решения стандартными средствами мониторинга компании. Средство мониторинга должно обеспечивать получение информации о работоспособности и доступности системы в объеме, достаточном для выявления и устранения нарушений в работе системы и её компонентов в соответствии с требованиями Части 6 данного Сборника.
Решение, накапливающее данные, должно иметь механизмы регулярной очистки или вытеснения оперативных данных в архив.При необходимости, решение должно поддерживать работу с архивными данными.
Хранение файлов и медиаконтента в реляционных базах данных должно быть отделено от хранения основных транзакционных данных. Использование LOB-структур в базах данных, хранящих основные транзакционные данные, запрещено.
Система должна иметь назначенный класс критичности согласно методике Группы
Для системы должен быть определен SLA по производительности
Система должна удовлетворять определенному для неё SLA по производительности
Для системы должен быть определен SLA по масштабируемости
Система должна удовлетворять определенному для неё SLA по масштабируемости
Для системы должен быть определен SLA по отказоустойчивости
Система должна удовлетворять определенному для неё SLA по отказоустойчивости
Для системы должен быть определен SLA по доступности
Система должна удовлетворять определенному для неё SLA по доступности
Для системы должен быть определен SLA по катастрофоустойчивости
Система должна удовлетворять определенному для неё SLA по катастрофоустойчивости
Для обеспечения требований катастрофоустойчивости, АС должна иметь резервную копию в резервном ЦОД с определенными параметрами RTO и RPO. Уровни резервирования оборудования и данных для АС должны соответствовать следующим параметрам: 1. Уровень резервирования серверного оборудования: МС - 100% резерв BC - 100% резерв BO - <= 100% OP - <= 100%\n2. Уровень резервирования данных: MC - 100% реплика BC - 100% реплика BO - 100% реплика,восстановление из бэкапа и/или загрузка из систем-источников OP - <= 100%, восстановление из бэкапа и/или загрузка из систем-источников\n3.Требования по методу переключения: MC - Автоматическое BC - Автоматическое BO - Автоматическое /Ручное OP - Автоматическое /Ручное
В случае использования технологии автоматизации бизнес процессов RPA (Robotic process automation), требуется сохранить сценарий ручного выполнения операций для разбора исключительных ситуаций, требующих вмешательства человека, и/или реализацию процесса на период недоступности RPA
В случае, если для взаимодействия с решением используется исключительно API (у решения отсутствует графический интерфейс пользователя), использование технологии автоматизации бизнес процессов RPA (Robotic process automation) в решении запрещено
Выполнение алгоритмов технологии автоматизации бизнес процессов RPA (Robotic process automation) разрешено только на инфраструктуре, изолированной от рабочих мест пользователей
В случае использования технологии автоматизации бизнес процессов RPA (Robotic process automation), запрещается хранение конфиденциальной информации и бизнес-информации автоматизируемых процессов в системах хранения данных RPA (за исключением временного сохранения состояния шага процесса алгоритма в очереди RPA и аудита). По окончанию обработки информации или окончанию своей работы RPA-алгоритмы должны удалять временно сохранённую информацию.
В случае использования технологии автоматизации бизнес процессов RPA (Robotic process automation), для передачи задачи между роботами требуется использовать средства платформы RPA или внешний оркестратор. Передача задач между роботами через файловые интеграционные ресурсы и электронную почту запрещена.
Привилегированный доступ к компонентам системы должен обеспечиваться посредством системы контроля привилегированного доступа (PAM). Разрешено использовать только системы PAM, удовлетворяющие требованию TACAP_2-Ч07.ПА-10-03
Внешние сервисы компании должны размещаться по принципу: - Публичная точка доступа к сервису, реализующая механизм вызова сервиса, размещается во внешнем сегменте сети (DMZ). - Основная компонента системы, выполняющая бизнес-логику сервиса, размещается в защищенном внутреннем сегменте сети
Исходящий внешний сетевой трафик системы, хранящей и/или обрабатывающей конфиденциальные данные, должен анализироваться системой предотвращения утечек конфиденциальной информации.  Список автоматизированных систем и потоков, подлежащих контролю со стороны системы предотвращения утечек конфиденциальной информации, определяется подразделением компании, выполняющим функции кибербезопасности. Разрешено использовать только системы предотвращения утечек конфиденциальной информации, удовлетворяющие требованию TACAP_2-Ч07.ПА-10-03
При взаимодействии с информационными системами компании из сети Интернет или иных внешних сетей, необходимо обеспечить шифрование канала связи согласно требованиям подразделения компании, ответственного за кибербезопасность
При передаче конфиденциальной информации между автоматизированными системами (включая все промежуточные интеграционные компоненты) должны использоваться средства криптографической защиты для шифрования конфиденциальной информации. Правила шифрования конфиденциальной информации при передаче между автоматизированными системами определяются подразделением компании, выполняющим функции кибербезопасности.
Доступ к внутренним электронным ресурсам компании из сети Интернет или иных внешних сетей должен быть ограничен посредством организации подключения через специализированный VPN-шлюз во внешнем сегменте (DMZ) сети компании.
"Подключение к виртуальной частной сети (VPN) должно осуществляться с использованием:\n - либо двухфакторной аутентификации\n - либо TLS-сертификата\nПриоритетным является использование двухфакторной аутентификации.
Требуется обеспечить разграничение доступа пользователей к автоматизированной системе на уровне операций и на уровне данных посредством механизма ролей
Управление ролями пользователей должно производиться централизовано на уровне компании
Управление доступом пользователей должно производиться централизовано на уровне компании
Автоматизированная система должна позволять протоколировать события безопасности и действия пользователей. Содержимое, объем, полноту и место хранения данных для протоколирования определяет подразделение компании, исполняющее функции кибербезопасности.
Конфиденциальная информация,содержащаяся в логах должна быть маскирована или защищена в соответствии с требованиями подразделения компании, ответственного за кибербезопасность
Запрещается выгрузка из системы конфиденциальных данных на рабочую станцию пользователя,за исключением выгрузок на защищенные виртуальные рабочие станции, печатных форм и отчетов, программного кода при разработке. Для таких исключений в системе должна быть разработана отдельная роль, которая разрешает выгрузку конфиденциальных данных в конкретном случае, а также необходимо реализовать журналирование событий выгрузки конфиденциальных данных
При доступе к виртуальному АРМ, на котором обрабатывается конфиденциальная информация, запрещено использование буфера обмена и подключение дисков физического ПК пользователя).
Запрещается выгрузка из системы конфиденциальных данных на файловые ресурсы. Исключением является интеграция через защищенный файловый интеграционный ресурс, разрешенный к использованию подразделением компании, ответственным за кибербезопасность. При этом доступ к файловому ресурсу разрешен только через техническую учетную запись этой системы.
Запрещена почтовая пересылка конфиденциальных данных и персональных данных в рамках автоматизации исполнения бизнес-процессов (за исключением требований регуляторов).
Запрещается формирование системойфайлов и сообщений, содержащих конфиденциальную информацию, на ресурсах, доступ к которым не определяется политикой доступа к ресурсам, согласованной подразделением, выполняющим функции кибербезопасности в компании
Хранение и обработка данных, подпадающих под требования PCI DSS, должно соответствовать требованиям PCI DSS и подразделения компании, ответственного за кибербезопасность
Автоматизированная система должна иметь (встроенный или внешний) механизм обезличивания конфиденциальных данных при наличии конфиденциальных данных.
Запрещен доступ из тестовых сред к необезличенным конфиденциальным данным, выгруженным из промышленного контура
Запрещено хранение конфиденциальных данных во внешнем сегменте (DMZ) корпоративной сети.
Запрещается передача конфиденциальных данных во внешнем сегменте (DMZ) корпоративной сети в незашифрованном виде.
Запрещено использование самоподписанных сертификатов в промышленной среде. В промышленной среде разрешается использовать только сертификаты, выданные удостоверяющими центрами страны регистрации компании, а так же удостоверяющими центрами, одобренными подразделением, выполняющим функции кибербезопасности в компании
В случае собственной разработки системы, репозитории хранения исходного кода и библиотек должны быть одобрены к использованию подразделением компании, исполняющим функции кибербезопасности
Компоненты системы должны проходить контроль безопасности и проверку на отсутствие известных уязвимостей по реестрам уязвимостей. Список компонентов и реестры уязвимостей для проверки определяются подразделением компании, исполняющим функции кибербезопасности.
Предоставляемые системой интерфейсы интеграции (API) должны быть задокументированы.
Запрещена интеграция системы с другими системами компании с использованием почтовых серверов и протоколов (за исключением непосредственной рассылки сообщений потребителям - пользователям, клиентам)
В случае интеграции систем посредством обмена файлами через файловый интеграционный ресурс, необходимо обеспечить доступ к ресурсу, на который осуществляется выгрузка, только технологическим учетным записям системы-источника и системы-получателя
В случае интеграции систем посредством обмена файлами через файловый интеграционный ресурс, необходимо обеспечить удаление файлов с ресурса в автоматическом режиме. Правила и сценарии удаления файлов из файлового интеграционного ресурса должны соответствовать требованиям подразделения, выполняющего функции кибербезопасности в компании.
В случае интеграции систем посредством обмена файлами через файловый интеграционный ресурс, данный файловый интеграционный ресурс должен быть одобрен к использованию подразделением компании, ответственным за кибербезопасность.
Запрещена интеграция системы с другими информационными системами с использованием DBLink (привязка БД одной системы к БД другой системы) в любой форме, создание новых и расширение существующих DBLink
Запрещена интеграция системы с другими информационными системами с использованием прямых протоколов доступа к подсистеме хранения данных (СУБД), в том числе ODBC, JDBC - доступ одной системы к БД другой системы. Требование не распространяется на: инструменты ETL; интеграционные площадки; системы, обеспечивающие функции безопасности, надежности, отказоустойчивости, инфраструктурные функции – логирование, мониторинг, резервное копирование, и т.п.; системы, обеспечивающие визуализацию отчетности; доступ к данным в хранилище данных.
Запрещается передача между системами компании и системами партнёров компании структурированных данных без проверки по схеме, описывающей структуру прикладных данных (в том числе, XMLSchema, JSON Schema и другие).
В случае, если решение используется для предоставления Продуктов Экосистемы посредством API, информация об API должна быть опубликована в Каталоге API Экосистемы.
При синхронном обращении к управляемым инфраструктурным сервисам необходимо обеспечить корректную обработку ошибок вызываемых сервисов
Компании необходимо иметь и поддерживать в актуальном состоянии список разрешенных к использованию сайдкаров. Разрешено использовать только сайдкары, внесенные в список разрешенных к использованию сайдкаров.
Приложение должно позволять сменить детализацию уровня логирования в run-time для всех экземпляров исполняемого компонента, входящего в приложение, без перезагрузки этих экземпляров
Запрещено использовать один Configmap несколькими исполняемыми компонентами приложения
Для каждого вызова метода внешнего или внутреннего исполняемого компонента кроме событийного взаимодействия должны быть реализованы circuit breaker
Для взаимодействия с API cloud native приложения или между исполняемыми компонентами cloud native приложения должны использоваться протоколы REST-based API (level 1 и выше), JSON-RPC; gRPC; graphQL, Transit
Для взаимодействия с API cloud native приложения или между исполняемыми компонентами cloud native приложения должны использоваться форматы передаваемых данных: XML JSON Avro Protobuf, EDN
Для каждого контейнера должна быть реализована функция мониторинга (механизм реализации pull или push) [за исключением сайдкаров из утвержденного списка]. В случае использования pull мониторинга метрики должны экспортироваться в выделенный endpoint в формате Prometheus exposition format или Open Metrics
Для исполняемого компонента должен быть задан способ обработки прихода сигнала аварийного прерывания работы либо на уровне настроек среды исполнения либо на уровне программного кода приложения
Обращение по IP адресам к исполняемым компонентам и управляемым инфраструктурным сервисам допустимо только для отладки, поиска ошибок и решения инцидента. Для штатной эксплуатации необходимо использовать обращение по именам (URL/FQDN).
Для каждого контейнера,исключая список утверждённых сайдкаров, обязательно использование liveness probe, для которой должен быть разработан отдельный (уникальный) endpoint и указан в секции livenessProbe контейнера в единице развертывания оркестратора.
Для каждого контейнера, исключая список утверждённых сайдкаров обязательно использование readiness probe, для которой должен быть разработан отдельный (уникальный) endpoint и указан в секции readinessProbe контейнера в единице развертывания оркестратора.
Для каждого контейнера ,исключая список утверждённых сайдкаров в случае использования startup probe, для нее должен быть разработан отдельный (уникальный) эндпоинт и указан в секции startupProbe контейнера в единице развертывания оркестратора.
Для каждого компонента должен быть указан факт необходимости распределения экземпляров компонента по разным нодам среды исполнения Требования к равномерному распределению экземпляров компонент не предъявляются
TCP и shell-based пробы разрешены только для исполняемых компонент, не использующих http, http/2 протоколы (например, контейнеризированные очереди сообщений и inmemory кэши)
Для каждого из исполняемых компонент должен быть задан приоритет запуска средой исполнения
Тип обновления исполняемого компонента recreate запрещён
Период корректной остановки исполняемого компонента не должен превышать 60 секунд
В случае использования автоскейлинга должна быть отключена возможность блокировки миграции экземпляров исполняемого компонента по наличию файлов в emptydir
При выполнении последовательного обновления запрещено уменьшать количество экземпляров сервисов, обслуживающих текущие запросы
При выполнении последовательного обновления разрешено уменьшать количество экземпляров сервисов, обслуживающих текущие запросы, максимум на 25%
Количество попыток выполнения неуспешных проб до перезагрузки экземпляра исполняемого компонента не должно быть менее 3
Количество попыток выполнения неуспешных проб до вывода экземпляра исполняемого компонента из балансировки не должно быть менее 3
Время введения в балансировку (состояние ready) не должно превышать 90 секунд с момента старта контейнера, выполняющего бизнес-функцию.
При размещение приложения внутри проекта должна быть реализована модель безопасности "нулевого доверия" (zero trust). При обработке в проекте конфиденциальной информации все взаимодействия внутри проекта должны осуществляться с использованием TLS 1.2+ (шифрование).
Запрещается разворачивать приложения вне управляемой Среды исполнения. Запрещается использование средств контейнеризации вне среды исполнения.
В приложении запрещается использовать любые решения, требующие персистентного хранения обрабатываемых приложением данных в среде исполнения
Запрещается использовать приложения, требующие для своего функционирования привилегированной доступ на уровне узла кластера,среды исполнения или к средствам управления средой исполнения
Образы контейнеров приложений должны быть получены из утвержденного в компании централизованного репозитория образов контейнеров
Для хранения ключей, сертификатов, паролей, токенов, необходимых для работы контейнеров Приложения, должны использоваться объекты среды исполнения типа "secrets" или использовать секрет-менеджер. Объекты типа "secrets" должны поставляться в приложение с помощью средств среды исполнения.
Размещение различных АС в одном пространстве имён (namespace) разрешается только по согласованию с подразделением компании, исполняющим функции кибербезопасности.
Запрещено взаимодействие подов двух различных проектов напрямую. Взаимодействия между проектами должны проходить через ingress/egress proxy.
Все входящие запросы (в проект) должны проходить через ingress-proxy. Все исходящие запросы (из проекта) должны проходить через egress-proxy. При этом для входящих/исходящих взаимодействий должен использоваться mTLS 1.2+.
Ingress/Egress proxy должен размещаться внутри проекта.
Для всех входящих и исходящих взаимодействий проекта (неймспейса) должны быть реализованы механизмы аутентификации и авторизации (как для входящих, так и для исходящих запросов). При этом в подах ingress/egress proxy должен быть исключен прикладной функционал.
Запрещается запускать приложения, требующие изменения или удаления объектов NetworkPolicy, создаваемых по умолчанию
Запрещается запускать приложения, требующие использования сетевых интерфейсов и сетевых портов операционной системы узла кластера
Необходимо обеспечить наличие в Deployment,DeploymentConfig, StatefulSet, Job, CronJob только одного исполняемого компонента не включая сайдкары из утвержденного списка
Необходимо гарантировать работу приложения с количеством реплик пода от 2 и более В случае если компонент (pod) является периодически запускаемым (тип единицы развертывания = Job, CronJob), то для него данное требование не является обязательным
Необходимо использовать образы контейнеров с максимальным размером не более 1024 Мб для приложений, не реализующих задачи машинного обучения
Для приложений, реализующих задачи машинного обучения, необходимо использовать образы контейнеров с максимальным размером не более 10 Gb
Необходимо использовать поды с максимум 8 Гб памяти для приложений, не реализующих задачи машинного обучения
Необходимо использовать поды с максимум 4 ядрами для приложений, не реализующих задачи машинного обучения
Для приложений, реализующих задачи машинного обучения, необходимо использовать поды с максимум 32 Гб памяти
Для приложений, реализующих задачи машинного обучения, необходимо использовать поды с максимум 8 ядрами
Необходимо использовать ОС контейнера из  собственного registry компании, либо из registry, согласованного с подразделением кибербезопасности компании
Запрещена прямая привязка исполняемых компонентов к нодам
В случае использования JVM, должна использоваться версия jvm, способная получать параметры памяти request и limit из среды исполнения или в явном виде должны быть заданы границы параметров памяти
Временное хранилище для пода не должно превышать 2.5 ГБ
Запрещено создавать Pod Disruption Budget (PDB) с указанием значений полей minAvailable и maxUnavailable в процентах. Манифест PDB должен содержать либо поле .spec.minAvailable либо поле .spec.maxUnavailable. Значение поля minAvailable должно быть меньше количества реплик подов соответствующего Deployment/DeploymentConfig/ReplicationController/ReplicaSet/StatefulSet. Значение поля maxUnavailable должно быть больше 0.
Минимальная кратность георезервирования ТК (серверов, данных) АС должна быть равна m=1 (100%) с автоматическим переключением на резерв
Собственные инструменты администрирования, разработанные вендорами или внутренними подразделениями, при помощи которых возможно выполнение операций по внесению изменений, настройке ППО или проведению инфраструктурных работ на промышленном стенде, должны быть выделены как отдельные объекты учета в реестре ИТ-объектов компании
Должен быть реализован Контроль второй рукой (КВР) для выделенных потенциально деструктивных операций, которые осуществляются в инструментах администрирования АС, разработанных вендорами или внутренними подразделениями, при помощи которых возможно выполнение операций по внесению изменений, настройке ППО или проведению инфраструктурных работ на промышленном стенде АС
АС и ее компоненты должны использовать автоматизированное развертывание своих ТК.
При наличии stateful-компонентов АС должна включать прикладное решение по обеспечению высокой доступности (HA/DR), реализованное на основе одного из архитектурных паттернов: Stand-In (SI) Active-Active Parallel Run или разработанного собственного решения.
АС должна предусматривать встроенные и/или внешние механизмы ограничения потока входящих запросов с целью исключения ситуаций переполнения/конкуренции (режим работы под повышенной нагрузкой).
В случае использования общего балансировщика  нагрузки для нескольких АС, на данном балансировщике нагрузки должно обеспечиваться квотирование нагрузки для каждой АС в балансировке в отдельности
В случае использования общего балансировщика  нагрузки для нескольких потребителей сервиса, на данном балансировщике нагрузки должно обеспечиваться квотирование нагрузки для каждого потребителя сервиса в отдельности
Конфигурационные настройки АС должны храниться в персистентных технологических компонентах АС
ТК разных групп технологий не должны размещаться на одном ТР
Запрещено размещать несколько баз данных разных АС или разных стендов или разных классов критичности на одном экземпляре СУБД.
1. Запрещается фиксация в программном коде как IP-адресов, так и FQDN-имен. 2. Параметры сетевой адресации (FQDN, IP) должны быть вынесены в конфигурационные файлы либо настроечные таблицы. 3. По умолчанию АС должна работать с использованием FQDN-адресации. 4. В случае инцидентов, в качестве обходного решения для устранения ошибок в работе АС или инфраструктуры, допускается временное применение IP-адресации в конфигурационных файлах или настроечных таблицах.
При проектировании не допускается использование технологических решений требующих от сетевой инфраструктуры работы в растянутых (между ЦОДами) VLAN и/или через L2 Core.
При построении системы репликации для БД должны использоваться механизмы репликации средствами приложения и/или БД без задействования ТК, использующих механизмы репликации ОС/СХД.
Работоспособность ТК не должна зависеть от гипервизора, на котором размещена виртуальная машина Примеры: не иметь проброса внутрь ВМ дисков (RDM), внешних устройств (например USB), использовать установленные в гипервизор аппаратные компоненты (например видеокарта). Исключением из данного требования является использование аппаратных компонентов, одобренных к использованию подразделениями компании, отвечающими за надёжность ИТ-инфраструктуры.
ТК должны поддерживать смену IP-адреса ВМ во время работы или при рестарте, без влияния на прикладное ПО, опираясь на FQDN имена.
ТК должны поддерживать миграцию виртуальных машин между физическими хостами и дисковыми томами (live migration), выполняемую в рамках работы штатных механизмов платформы виртуализации
Полнофункциональный Stand-In должен являться эквивалентом Мастера по мощности (иметь аналогичную Мастеру производительность)
Полнофункциональный Stand-In должен обеспечивать выполнение всех сервисов Мастера.
Полнофункциональный Stand-In должен содержать весь набор данных.
Полнофункциональный Stand-In не налагает ограничений на время активной работы (активного состояния).
Только полнофункциональный Stand-In может становиться Мастером.
Ограниченный Stand-In : -должен поддерживать выполнение транзакционных online операций АС для клиентов согласно SLA для АС -должен использовать необходимый и достаточный объем данных для проведения операций -имеет ограниченное время работы (активного состояния), после которого необходимо переключение в исходное состояние.
Режим Ограниченного Stand-In должен удовлетворять SLA для АС
Репликация на Stand-In должна осуществляться в непрерывном, автоматическом режиме. Репликация данных между Основным и SI контуром должна проходить в режиме реального времени с контролем полноты, целостности, журналированием ошибок в ходе передачи данных между Основным и SI контуром.
Должны быть предусмотрены следующие варианты переключения на Stand-In: ·ручное переключение; ·автоматическое переключение.
Механизм переключения на  SI должен обеспечивать: ·автоматическое выявление состояний, требующих переключения контуров; ·остановку входного потока на контур с выявленными отклонениями (сбой, деградация) (и перевод его из состояния Активен) по срабатыванию критериев автоматического переключения или по команде администратора; ·где применимо – удержание входного потока в интервале ожидания «доката» репликации на контур-получатель; ·получение от контура-получателя статуса готовности; ·перенаправление входного потока на контур получатель.
Для каждой системы должны быть определены требования с критериями по переходу в режим SI в случае инцидента или деградации сервиса.
Автоматическое переключение выполняется при достижении Активным контуром заданных Критериев переключения, идентифицированных системой мониторинга.
Критерии переключения должны определяться с учетом возможности ложных срабатываний.
Критерии переключения до включения полностью автоматического режима должны быть протестированы на практике на предмет ложных срабатываний.
При достижении Критериев переключения должна быть доступна информация о состоянии, достаточная для заведения инцидента в системе управления инцидентами и оповещения заинтересованных сторон (включая другие АС)
В интерфейсе администратора АС необходимо наличие функции ручного переключения между контурами
Необходимо наличие механизма постепенного переключения нагрузки при переключении контуров. В том числе, при переключении на Основной контур при выходе из SI в режиме штатного функционирования.
Необходимо наличие механизма ограничения возможности единовременного перевода нагрузки на контур-получателя при переключении. В том числе, при переключении на Основной контур при выходе из SI в режиме штатного функционирования.
Необходимо наличие механизма явного подтверждения со стороны администраторов о принятом решении о моментальном подключении входного потока запросов без ограничений. При необходимости выполнения моментального подключения входного потока запросов без ограничений администраторам должно выдаваться предупреждение и требоваться явное подтверждение.
Требования SI-SWI-AC-01, SI-SWI-AC-02, SI-SWI-AC-03 могут быть признаны необязательными при наличии: -Положительного заключения об отсутствии нарушений штатной работы при отработке переключений под продолжительной пиковой нагрузкой по результатам нагрузочных испытаний; -Согласования решения о необязательности вышеуказанных требований с владельцем АС / сервиса. Пиковая нагрузка должна быть рассчитана с учетом роста объемов при целевых параметрах использования на горизонт планирования.
Необходимо наличие механизма защиты от шторма запросов и повторных запросов Варианты реализации: ·часть операций накапливается и приходит сразу после того, как контур становится доступным; ·пользователи, получая отказ в обслуживании в интервале недоступности, выполняют запросы повторно, создавая повторные запросы; ·компоненты в цепочке предоставления сервиса также могут обрабатывать возникающие ошибки и автоматически формировать повторы операций. Должны быть предусмотрены: ·ограничение количества запросов в единицу времени; ·увеличение таймаута ожидания при повторах; ·контроль количества повторов – при большом количестве повторных запросов на время блокировать их источник. Как вариант: отключение повторов.
Механизм репликации должен обеспечивать гарантированную передачу изменений из контура-источника в контур-получатель.
Механизм репликации должен обеспечивать контроль полноты и целостности передаваемых данных на всем протяжении от момента передачи на контуре-источнике до применения на контуре-получателе.
Необходим механизм автоматического выявления нарушения полноты и целостности передаваемых данных и обработки исключительных ситуаций в ходе репликации.
Временная рассинхронизация Основного и SI контуров допустима в границах задержки процесса репликации, которая, в случае переключения, не приведет к нарушению.SLA
Необходимо наличие дополнительного механизма проверки консистентности данных на Основном и SI контурах в виде сверки, в том числе встроенными средствами механизма репликации.
В режиме SI все операции, которые обрабатываются на контуре SI, должны иметь такие же характеристики производительности, как на Основном контуре.
Недоступность сервисов в процессе переключения контуров должна соответствовать показателю RTO для системы
Время принятия решения о переключении должно быть определено в SLA для АС
Время нахождения в SI при плановых работах: должно быть указано в SLA для АС
Для сервисов/АС, в которых есть требования по началу работы в режиме SI после обязательного полного наката всех проведенных операций, время недоступности сервисов не должно превышать полного времени переключения между контурами.
Работа в режиме SI (все конфигурации) с учетом интервалов недоступности сервисов, возникающих при переключении контуров, не должна приводить к нарушениям SLA для АС.
Скорость работы сервисных операций в режиме SI должна соответствовать значениям, указанным в SLA для АС
Полнофункциональный SI, выполняющий роль резерва, должен располагаться в резервном ЦОД
Ограниченный SI не должен рассматривать как полноценный резерв для АС
Необходимо наличие методики по проверке готовности ИТ услуг к аварийной ситуации в части SI.
В случае наличия резервного контура по схеме Stand-In необходимо обеспечить размещение по следующим правилам: Master базы данных основного контура и контура Stand-In должны размещаться в отдельных друг от друга геораспределенных ЦОД (желательно, в разных зонах доступности). Stand-By базы данных основного контура и контура Stand-In должны размещаться в отдельных друг от друга геораспределенных ЦОД (желательно, в разных зонах доступности). Master база данных и ее Stand-by должны располагаться в разных геораспределенных ЦОД (желательно, в другой зоне доступности). Snand-in база данных и ее Stand-by должны располагаться на разных геораспределенных ЦОД (желательно, в другой зоне доступности). Тех. ресурсы и тех. компоненты Stand-in и основного контуров должны располагаться в разных сетевых сегментах (разные VLAN). Резервный контур Stand In должен быть размещен на отдельных от промышленного контура технологических ресурсах .
В Основном и SI режимах должны использоваться идентичные системы мониторинга, журналирования, аудита.  Переключение между данными режимами не должно влиять на непрерывность работы и не требовать дополнительных настроек систем мониторинга, журналирования, аудита, переключения в интерфейсах пользователей.
Состояние Основного и SI контуров, а так же информация о процессе репликации между контурами и переключении контуров, должны быть доступны системам мониторинга, журналирования, аудита.
Параметры хранения данных журналирования и аудита контура SI не должны отличаться от Основного контура.
Репликация данных между активными плечами баз данных должна осуществляться прикладным методом средствами приложения
Для баз данных, работающих в режиме active-active, допустима работа в двух или более ЦОД (желательно, в разных зонах доступности) при соблюдении требования по минимальной кратности георерезвирования ТК
Экземпляры должны размещаться в разных ЦОД или в разных зонах доступности (должны быть гео-резервированы).
Допускается применение внешних, по отношению к экземплярам, диспетчеризирующих компонентов, с условием их гео-резервирования (прикладными или системными средствам).
Должна быть предусмотрена взаимная сетевая доступность экземпляров для процедур восстановления данных после сбоя
Тракты данных существуют на экземплярах в параллельном режиме, и данные должны быть продублированы
На уровне прикладной логики должна быть реализована регулярная сверка данных между экземплярами.
На уровне прикладной логики должно быть реализовано ручное переключение между экземплярами.
На уровне прикладной логики должно быть реализовано автоматическое переключение с одного экземпляра на другой в случае обнаружение ситуации "Сбой/недоступность".
